{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Q:\n",
    "    \n",
    "    def __init__(self, nState, nAction, nodes, activations):\n",
    "        \n",
    "        self.nState   = nState  # The number of values in the state (size of the vector)\n",
    "        self.nAction  = nAction # The number of possible actions. 4 in this case. (Note: \n",
    "                                # the size of the vector will always be 1)\n",
    "        self.nodes       = nodes        # number of nodes per layer\n",
    "        self.activations = activations  # activation function used in each layer\n",
    "        self.weights1 = [] # Store all the static weights here\n",
    "        self.weights2 = [] # Store all the dynamic weights here\n",
    "        self.biases1  = [] # Store all the static weights here\n",
    "        self.biases2  = [] # Store all the dynamic weights here\n",
    "        self.assignFunctions   = []\n",
    "        self.updateWtFunctions = {} # functions for assignning values to all weights\n",
    "        self.placeholderNames = {}\n",
    "        self.gamma = 1\n",
    "\n",
    "        \n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        # self.epsilon = tf.placeholder_with_default(0.8, shape = (), name='epsilon')\n",
    "        self.epsilon = tf.placeholder(dtype=tf.float32, shape = (), name='epsilon')\n",
    "        \n",
    "        with tf.variable_scope('Inputs'):\n",
    "            self.stateInput  = tf.placeholder(tf.float32, shape=(nState,), name='stateInput')\n",
    "            self.placeholderNames['Inputs/stateInput'] = 'input the state vector (nState, )'\n",
    "            \n",
    "            self.actionInput = tf.placeholder(tf.float32, shape=(1,), name='actionInput')\n",
    "            self.placeholderNames['Inputs/actionInput'] = 'input the action (1,)'\n",
    "            \n",
    "            self.nextStateInput = tf.placeholder(tf.float32, shape=(nState,), name='nextStateInput')\n",
    "            self.placeholderNames['Inputs/nextStateInput'] = 'input the state vector for the next state (nState, )'\n",
    "            \n",
    "            self.rewardInput = tf.placeholder(tf.float32, shape=(), name='rewardInput')\n",
    "            self.placeholderNames['Inputs/rewardInput'] = 'reward for the next state ()'\n",
    "            \n",
    "        # A state goes in and a value vector is calculated for all actions. We shall\n",
    "        # later make a selection based upon the value functions of all the actions.\n",
    "        # This is why this is called value based methods ...\n",
    "        with tf.variable_scope('Combine'):\n",
    "            #self.inp = tf.concat([self.stateInput, self.actionInput], axis=0)\n",
    "            self.inp = self.stateInput * 1\n",
    "            self.inp = tf.reshape(self.inp, (-1, 1), name='Inp')\n",
    "            \n",
    "        self.forwardPass( tf.reshape(self.nextStateInput, (-1, 1)), \n",
    "                         'StableWts',  True)   # These will be the static weights\n",
    "        self.forwardPass( self.inp, 'DynamicWts', False) # These will be the dynamic weights\n",
    "        \n",
    "        # w1 = w2, assign all other weights ...\n",
    "        # --------------------------------------\n",
    "        self.assignFunctionsGenerate()\n",
    "        \n",
    "        self.maxAction    = self.policyMax(self.qVal1) # dynamic weights (current state)\n",
    "        self.greedyAction = self.policyEpsilonGreedy(self.qVal2) # static weights (next state)\n",
    "        \n",
    "        # Difference between policy and current action\n",
    "        # and all other error terms\n",
    "        # -------------------------------------------------\n",
    "        self.delta    = (self.rewardInput + self.gamma * self.qVal1[self.maxAction] - self.qVal2[self.greedyAction])\n",
    "        self.delta    = tf.reduce_mean(self.delta)\n",
    "        self.sqrErr   = self.delta**2\n",
    "        self.priority = tf.abs(self.delta)\n",
    "        \n",
    "        self.opt = tf.train.AdamOptimizer().minimize( self.sqrErr )\n",
    "        \n",
    "        \n",
    "        # self.policyError = self.qVal1\n",
    "        \n",
    "        self.init = tf.global_variables_initializer()\n",
    "        self.sess = tf.Session()\n",
    "        self.sess.run(self.init, feed_dict={self.epsilon:0.5})\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def close(self):\n",
    "        self.sess.close()\n",
    "    \n",
    "    def policyMax(self, inpVec, name='policyMax'):\n",
    "        with tf.variable_scope(name):\n",
    "            result = tf.argmax(inpVec, name='maxVal')[0]\n",
    "        return result\n",
    "    \n",
    "    def policyEpsilonGreedy(self, inpVec, name='policyEpsilonGreedy'):\n",
    "        '''\n",
    "        inpVec  -> input vector (either self.qVal1 or self.qVal2)\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        with tf.variable_scope(name):\n",
    "            \n",
    "            # This is not strictly epsilon greedy, but will do for now\n",
    "            result = tf.cond( tf.random_uniform(()) < self.epsilon, \n",
    "                       lambda : tf.multinomial( 10*tf.ones(( 1, self.nAction))  , 1)[0][0],\n",
    "                       lambda : self.policyMax(inpVec) )\n",
    "            \n",
    "        return result\n",
    "    \n",
    "    def assignFunctionsGenerate(self):\n",
    "\n",
    "        with tf.variable_scope('assignFunctions'):\n",
    "            \n",
    "            # ------------------------------------------------\n",
    "            # Generate functions that will allow us\n",
    "            # to update the static weights with the\n",
    "            # dynamic weights\n",
    "            # ------------------------------------------------            \n",
    "            for w1, w2 in zip(self.weights1, self.weights2):\n",
    "                self.assignFunctions.append( tf.assign( w1, w2 ) )\n",
    "\n",
    "            for w1, w2 in zip(self.biases1, self.biases2):\n",
    "                self.assignFunctions.append( tf.assign( w1, w2 ) )\n",
    "                \n",
    "            # ------------------------------------------------\n",
    "            # We also need something that will allow us to put \n",
    "            # values into each of the weights if necessary\n",
    "            # ------------------------------------------------\n",
    "            for i, w in enumerate(self.weights1):\n",
    "                p = tf.placeholder(tf.float32, \n",
    "                               w.shape, \n",
    "                               name='wStatic_{:05d}'.format( i ))\n",
    "                self.placeholderNames['assignFunctions/wStatic_{:05d}'.format( i )] = 'w1_[{}]'.format(i)\n",
    "                self.updateWtFunctions['wStatic_{:05d}'.format( i )] = tf.assign(w, p)\n",
    "                \n",
    "            for i, w in enumerate(self.biases1):\n",
    "                p = tf.placeholder(tf.float32, \n",
    "                               w.shape, \n",
    "                               name='bStatic_{:05d}'.format( i ))\n",
    "                self.placeholderNames['assignFunctions/bStatic_{:05d}'.format( i )] = 'b1_[{}]'.format(i)\n",
    "                self.updateWtFunctions['bStatic_{:05d}'.format( i )] = tf.assign(w, p)\n",
    "            \n",
    "            for i, w in enumerate(self.weights2):\n",
    "                p = tf.placeholder(tf.float32, \n",
    "                               w.shape, \n",
    "                               name='wDynamic_{:05d}'.format( i ))\n",
    "                self.placeholderNames['assignFunctions/wDynamic_{:05d}'.format( i )] = 'w2_{}'.format(i)\n",
    "                self.updateWtFunctions['wDynamic_{:05d}'.format( i )] = tf.assign(w, p)\n",
    "                \n",
    "            for i, w in enumerate(self.biases2):\n",
    "                p = tf.placeholder(tf.float32, \n",
    "                               w.shape, \n",
    "                               name='bDynamic_{:05d}'.format( i ))\n",
    "                self.placeholderNames['assignFunctions/bDynamic_{:05d}'.format( i )] = 'b2_{}'.format(i)\n",
    "                self.updateWtFunctions['bDynamic_{:05d}'.format( i )] = tf.assign(w, p)\n",
    "                \n",
    "            \n",
    "    \n",
    "    def forwardPass(self, inpVec, name ='StableWts', static=True):\n",
    "        \n",
    "        with tf.variable_scope(name):\n",
    "            \n",
    "            prevN = self.nState # +1 Note that we wil not add the action term\n",
    "            temp1 = inpVec * 1\n",
    "            for i, (n, a) in enumerate(zip(self.nodes, self.activations)):\n",
    "                with tf.variable_scope('layer_{:05d}'.format(i)):\n",
    "                    w = tf.Variable(0.1*np.random.rand(n, prevN).astype(np.float32), name='W')\n",
    "                    b = tf.Variable(np.zeros((n,1), np.float32), name='b')\n",
    "                    if a is not None:\n",
    "                        temp1 = a(tf.matmul( w, temp1 ) + b)\n",
    "                    else:\n",
    "                        temp1 = tf.matmul( w, temp1 ) + b\n",
    "                    \n",
    "                    prevN = n\n",
    "                    \n",
    "                    # Save them because we will have to update them\n",
    "                    # halfway into the program\n",
    "                    if static:\n",
    "                        self.weights1.append(w)\n",
    "                        self.biases1.append(b)\n",
    "                    else:\n",
    "                        self.weights2.append(w)\n",
    "                        self.biases2.append(b)\n",
    "                    \n",
    "            if static:\n",
    "                self.qVal1 = tf.multiply(temp1, 1, name='qVal1')\n",
    "            else:\n",
    "                self.qVal2 = tf.multiply(temp1, 1, name='qVal2')\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def updateStaticWeights(self):\n",
    "        for f in self.assignFunctions:\n",
    "            self.sess.run(f)\n",
    "        return\n",
    "    \n",
    "    def getWeights(self, static=True):\n",
    "        if static:\n",
    "            return self.sess.run(self.weights1+self.biases1)\n",
    "        else:\n",
    "            return self.sess.run(self.weights2+self.biases2)\n",
    "    \n",
    "    def run(self, s):\n",
    "        \n",
    "        result = self.sess.run([self.qVal1, self.qVal2], feed_dict = {\n",
    "            'Inputs/stateInput:0'     : s,\n",
    "            'Inputs/nextStateInput:0' : s,\n",
    "        })\n",
    "\n",
    "        return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "q = Q(36, 4, [3, 2, 4], [tf.tanh, tf.tanh, None]) # The last one is predicting a value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.00728514],\n",
       "        [0.00760357],\n",
       "        [0.01888298],\n",
       "        [0.01219106]], dtype=float32), array([[0.01616865],\n",
       "        [0.00955882],\n",
       "        [0.01626163],\n",
       "        [0.01275421]], dtype=float32)]"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.run(np.ones(36))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50271434"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.sess.run( q.delta, feed_dict = {\n",
    "    q.nextStateInput : np.ones(36),\n",
    "    q.stateInput     : np.ones(36),\n",
    "    q.epsilon        : 0.4,\n",
    "    'Inputs/rewardInput:0' : 0.5\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01616865]\n",
      " [0.00955882]\n",
      " [0.01626163]\n",
      " [0.01275421]]\n",
      "2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,\n"
     ]
    }
   ],
   "source": [
    "print( q.sess.run(\n",
    "    q.qVal2, \n",
    "    feed_dict={q.nextStateInput : np.ones(36), q.stateInput: np.ones(36)}))\n",
    "for i in range(30):\n",
    "    tempV = q.sess.run(q.maxAction, feed_dict={q.nextStateInput : np.ones(36), q.stateInput: np.ones(36)})\n",
    "    print(tempV, end=',')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00728514]\n",
      " [0.00760357]\n",
      " [0.01888298]\n",
      " [0.01219106]]\n",
      "2,2,3,0,3,1,2,1,3,0,2,0,2,2,0,2,0,0,0,3,0,1,2,2,1,3,2,1,2,2,2,1,1,2,1,0,0,3,2,1,2,2,0,1,3,2,2,2,2,0,2,0,0,0,1,0,3,3,3,1,0,0,2,2,1,2,3,2,1,0,2,0,0,2,2,1,1,1,0,1,1,3,2,2,1,3,2,1,2,0,2,3,3,2,2,1,0,0,2,3,\n"
     ]
    }
   ],
   "source": [
    "print( q.sess.run(\n",
    "    q.qVal1, \n",
    "    feed_dict={q.nextStateInput: np.ones(36)\n",
    "              }))\n",
    "for i in range(100):\n",
    "    \n",
    "    tempV = q.sess.run(q.greedyAction, \n",
    "                       feed_dict={\n",
    "                           q.stateInput: np.ones(36),\n",
    "                           q.nextStateInput: np.ones(36),\n",
    "                           q.epsilon : 0.9\n",
    "                       })\n",
    "    print(tempV, end=',')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wStatic_00000': <tf.Tensor 'assignFunctions/Assign_6:0' shape=(3, 36) dtype=float32_ref>,\n",
       " 'wStatic_00001': <tf.Tensor 'assignFunctions/Assign_7:0' shape=(2, 3) dtype=float32_ref>,\n",
       " 'wStatic_00002': <tf.Tensor 'assignFunctions/Assign_8:0' shape=(4, 2) dtype=float32_ref>,\n",
       " 'bStatic_00000': <tf.Tensor 'assignFunctions/Assign_9:0' shape=(3, 1) dtype=float32_ref>,\n",
       " 'bStatic_00001': <tf.Tensor 'assignFunctions/Assign_10:0' shape=(2, 1) dtype=float32_ref>,\n",
       " 'bStatic_00002': <tf.Tensor 'assignFunctions/Assign_11:0' shape=(4, 1) dtype=float32_ref>,\n",
       " 'wDynamic_00000': <tf.Tensor 'assignFunctions/Assign_12:0' shape=(3, 36) dtype=float32_ref>,\n",
       " 'wDynamic_00001': <tf.Tensor 'assignFunctions/Assign_13:0' shape=(2, 3) dtype=float32_ref>,\n",
       " 'wDynamic_00002': <tf.Tensor 'assignFunctions/Assign_14:0' shape=(4, 2) dtype=float32_ref>,\n",
       " 'bDynamic_00000': <tf.Tensor 'assignFunctions/Assign_15:0' shape=(3, 1) dtype=float32_ref>,\n",
       " 'bDynamic_00001': <tf.Tensor 'assignFunctions/Assign_16:0' shape=(2, 1) dtype=float32_ref>,\n",
       " 'bDynamic_00002': <tf.Tensor 'assignFunctions/Assign_17:0' shape=(4, 1) dtype=float32_ref>}"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.updateWtFunctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Inputs/stateInput': 'input the state vector (nState, )',\n",
       " 'Inputs/actionInput': 'input the action (1,)',\n",
       " 'Inputs/nextStateInput': 'input the state vector for the next state (nState, )',\n",
       " 'Inputs/rewardInput': 'reward for the next state ()',\n",
       " 'assignFunctions/wStatic_00000': 'w1_[0]',\n",
       " 'assignFunctions/wStatic_00001': 'w1_[1]',\n",
       " 'assignFunctions/wStatic_00002': 'w1_[2]',\n",
       " 'assignFunctions/bStatic_00000': 'b1_[0]',\n",
       " 'assignFunctions/bStatic_00001': 'b1_[1]',\n",
       " 'assignFunctions/bStatic_00002': 'b1_[2]',\n",
       " 'assignFunctions/wDynamic_00000': 'w2_0',\n",
       " 'assignFunctions/wDynamic_00001': 'w2_1',\n",
       " 'assignFunctions/wDynamic_00002': 'w2_2',\n",
       " 'assignFunctions/bDynamic_00000': 'b2_0',\n",
       " 'assignFunctions/bDynamic_00001': 'b2_1',\n",
       " 'assignFunctions/bDynamic_00002': 'b2_2'}"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.placeholderNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.03299291, 0.03517313, 0.01645651, 0.04629924, 0.07629357,\n",
       "         0.07499915, 0.0856449 , 0.04063104, 0.09009108, 0.09890855,\n",
       "         0.03721462, 0.03205042, 0.06937148, 0.055203  , 0.01992404,\n",
       "         0.06598932, 0.08348732, 0.05773957, 0.09873063, 0.06344263,\n",
       "         0.09118128, 0.05935813, 0.00305091, 0.09668633, 0.03166735,\n",
       "         0.0729511 , 0.01031388, 0.01391992, 0.04280156, 0.04658872,\n",
       "         0.00974948, 0.07108812, 0.00645686, 0.0474534 , 0.04956342,\n",
       "         0.08710636],\n",
       "        [0.09790519, 0.07749604, 0.01509659, 0.03200435, 0.02563003,\n",
       "         0.03834281, 0.02311203, 0.01210869, 0.04242229, 0.06922634,\n",
       "         0.06226359, 0.08525556, 0.03264777, 0.01629683, 0.04144548,\n",
       "         0.06429414, 0.03271007, 0.03990607, 0.07188293, 0.02998293,\n",
       "         0.06224615, 0.00102955, 0.06358358, 0.07353483, 0.0291667 ,\n",
       "         0.09187366, 0.05200893, 0.01049873, 0.09651186, 0.04837734,\n",
       "         0.00489965, 0.08283591, 0.04444638, 0.00819625, 0.05516007,\n",
       "         0.01235184],\n",
       "        [0.02259216, 0.08554925, 0.0616466 , 0.04044292, 0.02992496,\n",
       "         0.01071417, 0.00474118, 0.07868034, 0.01161189, 0.07326205,\n",
       "         0.02810067, 0.06037375, 0.06970982, 0.08554073, 0.06270985,\n",
       "         0.05666264, 0.02259011, 0.03570042, 0.00458563, 0.00247185,\n",
       "         0.03565382, 0.01455072, 0.02699495, 0.03985255, 0.04827949,\n",
       "         0.05179273, 0.07773163, 0.00337562, 0.01591225, 0.01518331,\n",
       "         0.04534861, 0.02757794, 0.07867675, 0.08092826, 0.02436562,\n",
       "         0.06764042]], dtype=float32),\n",
       " array([[0.05725872, 0.07028223, 0.04437311],\n",
       "        [0.04565675, 0.00105311, 0.02394548]], dtype=float32),\n",
       " array([[0.03193356, 0.03333797],\n",
       "        [0.04064149, 0.01726768],\n",
       "        [0.08255745, 0.08692418],\n",
       "        [0.04638612, 0.0726921 ]], dtype=float32),\n",
       " array([[0.],\n",
       "        [0.],\n",
       "        [0.]], dtype=float32),\n",
       " array([[0.],\n",
       "        [0.]], dtype=float32),\n",
       " array([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]], dtype=float32)]"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.getWeights(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.08625142, 0.04608831, 0.06468453, 0.09733008, 0.02491107,\n",
       "         0.08204471, 0.09346557, 0.09515753, 0.08359794, 0.06385153,\n",
       "         0.00373808, 0.02718518, 0.02246364, 0.02944267, 0.0657542 ,\n",
       "         0.0727488 , 0.09074577, 0.08526561, 0.09323161, 0.03843711,\n",
       "         0.01467886, 0.04171897, 0.0003069 , 0.06510345, 0.04899644,\n",
       "         0.05537335, 0.0463918 , 0.03897854, 0.03099833, 0.02034565,\n",
       "         0.06910374, 0.0618782 , 0.05305011, 0.09895297, 0.06035381,\n",
       "         0.07349762],\n",
       "        [0.06854769, 0.00095459, 0.0285784 , 0.03041754, 0.0331983 ,\n",
       "         0.0205536 , 0.01216186, 0.08983107, 0.07342849, 0.03427576,\n",
       "         0.00819802, 0.08042007, 0.02022109, 0.04257431, 0.00727592,\n",
       "         0.05225666, 0.0928688 , 0.04494976, 0.09078857, 0.09893838,\n",
       "         0.09578388, 0.02929911, 0.09645609, 0.00122733, 0.08841099,\n",
       "         0.06323704, 0.04449945, 0.09391238, 0.06188601, 0.07680024,\n",
       "         0.02170859, 0.05462886, 0.01623207, 0.08281913, 0.02752188,\n",
       "         0.08473264],\n",
       "        [0.07184794, 0.07186153, 0.04836921, 0.01973256, 0.05856493,\n",
       "         0.07319361, 0.00790111, 0.08669584, 0.03753034, 0.01565129,\n",
       "         0.06159636, 0.05498363, 0.07383134, 0.01808523, 0.08730737,\n",
       "         0.00203966, 0.02233096, 0.02155196, 0.06204797, 0.01685542,\n",
       "         0.04931398, 0.01687697, 0.08528667, 0.01640422, 0.09567308,\n",
       "         0.01788928, 0.00033342, 0.05631337, 0.01216865, 0.04031536,\n",
       "         0.03348665, 0.06107224, 0.06098919, 0.06165037, 0.00792087,\n",
       "         0.07017619]], dtype=float32),\n",
       " array([[0.09255345, 0.05431437, 0.04340274],\n",
       "        [0.03630561, 0.07102016, 0.05209041]], dtype=float32),\n",
       " array([[0.05218443, 0.04549447],\n",
       "        [0.02871053, 0.02946053],\n",
       "        [0.06094876, 0.03561594],\n",
       "        [0.06652746, 0.00550216]], dtype=float32),\n",
       " array([[0.],\n",
       "        [0.],\n",
       "        [0.]], dtype=float32),\n",
       " array([[0.],\n",
       "        [0.]], dtype=float32),\n",
       " array([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]], dtype=float32)]"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.getWeights(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "q.updateStaticWeights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "q.sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will not work in real code ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2,1,3,1,0,3,1,3,3,3,3,3,1,0,2,3,3,0,3,3,0,0,2,3,0,3,3,3,2,1,2,3,3,3,1,1,3,3,3,3,3,3,3,3,3,2,0,1,3,2,3,3,0,0,2,3,0,1,1,0,3,0,2,1,1,1,0,3,3,0,3,2,3,3,0,3,0,3,0,3,2,3,3,3,3,1,2,1,2,0,3,1,3,0,3,0,3,3,3,0,\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "inpVec = tf.placeholder(shape=(4,), dtype=tf.float32)\n",
    "\n",
    "epsilon   = tf.convert_to_tensor(0.5) \n",
    "probMax   = 1 - epsilon\n",
    "probOther = epsilon/( 4 - 1 )\n",
    "\n",
    "temp  = tf.ones(shape=(4,))*probOther\n",
    "temp  = tf.Variable(temp)\n",
    "temp  = temp[ tf.argmax(inpVec) ].assign( probMax )\n",
    "temp1 = tf.multinomial(tf.log( tf.reshape(temp, shape=(1, -1))  ), 1)[0][0]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(100):\n",
    "        temp_V = sess.run(temp1, feed_dict={ inpVec : np.array([1,2,3,4]) })\n",
    "        print(temp_V, end=',')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.00000001"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([0.16666667, 0.16666667, 0.16666667, 0.5       ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
